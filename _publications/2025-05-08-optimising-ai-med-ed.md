---
title: "Optimising AI in Medical Education: Cost-Benefit Analysis of Large Language Models in the MIR Examination"
collection: publications
category: manuscripts
permalink: /publication/2025-05-08-optimising-ai-med-ed
excerpt: "Cost–benefit evaluation of 22 large language models on Spain's MIR 2024/2025 exams, introducing a *cost-per-correct-answer* metric."
date: 2025-05-08
venue: "8ᵗʰ International Scientific Conference on Business and Economics (ISCBE 2025), Tetovo"
paperurl: ""
bibtexurl: ""
citation: "Carlos Luengo Vera, Antonio J. de Lucas López, Víctor Ramos Arroyo & M. Teresa de Val Núñez (2025). *Optimising AI in Medical Education: Cost-Benefit Analysis of Large Language Models in the MIR Examination.* Paper presented at the 8ᵗʰ ISCBE (Tetovo, 08–09 May 2025); manuscript under review for Springer proceedings."
tags:
  - Large Language Models
  - Cost-Benefit Analysis
  - MIR Exam
  - Medical AI
  - Educational Technology
image: /images/post/2025/2025_mir_cost_benefit.png
---

> **Publication status:** The full paper was **accepted for oral presentation** at **ISCBE 2025** and is now **under peer review for inclusion in the Springer conference proceedings**. It will be released open-access upon publication.  

## Abstract  
This study examines the economic sustainability of deploying large language models (LLMs) in high-stakes medical testing. Twenty-two models—ranging from premium general-purpose systems (GPT-4 Turbo, Claude Sonet 3.5, Gemini 1.5 Pro) to domain-specific engines (Miri Pro)—were benchmarked on the 210-item Spanish Medical Intern Resident (MIR) examinations for 2024 and 2025. Results show that **Miri Pro achieved 95.6 % accuracy (195/210) at a cost of just $0.0125 per correct answer**, outperforming both human top-scorers and higher-priced models such as OpenAI o1.

## Methods  
- **Dataset:** Official MIR 2024 & 2025 questions, including 25 image-based items.  
- **Evaluation protocol:** Zero-shot prompting; no model pre-exposure to the dataset.  
- **Metrics:** Raw accuracy, token consumption, API cost, and a novel **cost-per-correct-response** indicator.  
- **Statistics:** Paired *t*-tests, ANOVA and linear regression to explore cost–accuracy relationships.

## Key Findings  
* Fine-tuned models (Miri Pro, Claude Sonet 3.5) deliver the **best accuracy-to-cost balance**; premium generalists exhibit diminishing returns.  
* **Low-cost models** (AWS Nova Micro, Claude Haiku 3.5) maintain competitive accuracy while slashing operating costs, making them attractive for resource-constrained settings.  
* **Multimodal systems** (Gemini Vision Pro, Grok Vision Beta) dominate image-recognition tasks, whereas text-optimised models lose up to 30 percentage points on visual items.  
* The **cost–accuracy correlation is non-linear**—higher spend does not guarantee proportionally higher performance.

## Practical Implications  
1. **Adopt fine-tuned, domain-specific AI** to maximise learning gains without incurring prohibitive costs.  
2. Integrate **multimodal capability** where image interpretation is core to assessment.  
3. Use **cost-per-correct-answer** as an institutional purchasing metric to ensure fiscal responsibility.  
4. Regulators should promote **transparent pricing and equitable access** to prevent widening the digital divide in medical education.

**Comments:** 34 pages, 2 tables, 6 figures.  
**Conference:** 8ᵗʰ ISCBE 2025 – "Economic Resilience & Sustainability: Contemporary Challenges" (Tetovo, North Macedonia).

*This work offers a blueprint for selecting AI models that balance pedagogical impact with economic feasibility, guiding educators, policymakers and developers toward sustainable AI integration in clinical training.* 